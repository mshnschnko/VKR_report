\chapter{Постановка задачи и обзор решений} \label{ch1}
\textit{Задача фокусировки} -- нахождение положения линзы или системы линз относительно матрицы камеры, в котором снимок объекта будет максимально четким, то есть наведение объекта схемки на резкость.

\textit{Автофокусировка} -- фокусировка, которая осуществляется алгоритмом без участия человека.

\textit{Цифровой микроскоп} -- вид оптического (светового) микроскопа, в котором для наблюдения объекта используется цифровая камера вместо окуляров или вместе с ними.

Необходимо разработать новый алгоритм автофокусировки цифрового микроскопа, который отличался бы легкостью применения, высокими скоростью работы и метриками качества даже при наличии шума. Кроме того, алгоритм должен работать исключительно с изображениями с камеры, то есть без применения каких-либо дополнительных датчиков.

\section{Существующие классические методы автофокусировки} \label{ch1:sec1}
Существует множество классических методов автофокусировки. Например, контрастный, фазовый (Phase-Detection Autofocus или PDAF) или аналитический метод на основе оценки резкости изображения. В этом параграфе будут рассмотрены их алгоритмы работы.

\subsection{Метод анализа резкости}
Аналитический метод является наиболее простым и примитивным, но из-за этого наименее эффективным. Данный алгоритм работает на основе расчета резкости изображения. Сама же резкость рассчитывается путем нахождения дисперсии лапласиана в каждой точке снимка. 

Лапласиан является мерой второй производной и используется для поиска областей с быстрой сменой яркости. Чем выше дисперсия Лапласиана по всему изображению, тем выше <<четкость>> этого изображения. Аналитически лапласиан определяется формулой
\begin{equation}
	L=\frac{\partial^2 f}{\partial x^2} + \frac{\partial^2 f}{\partial y^2}
\end{equation}

Однако при работе с изображением, то есть с матрицей чисел, возникает трудность в применении данной формулы, так как нет явной функции, которая описывала бы сделанный снимок. Чтобы решить эту проблему, необходимо более детально рассмотреть, что из себя представляет лапласиан. Лапласиан есть дивергенция градиента заданной функции:
\begin{equation}
	\nabla F = \text{div}\ \text{grad} F
\end{equation}

Приблизительно рассчитать градиент в точке можно с помощью оператора Собеля \cite{SobelOperator}. Оператор Собеля представляет собой дискретный дифференциальный оператор, вычисляющий приближённое значение градиента яркости изображения. Данный оператор производит свертку исходного изображения с ядрами размера $3 \times 3$.

Пусть \textbf{A} -- исходное изображение, $\textbf{G}_x$ и $\textbf{G}_y$ -- изображения, каждая точка которых является приблизительным значением производной по $x$ и $y$ соответственно.
\begin{equation}
	\textbf{G}_x =
	\begin{bmatrix}
		-1 & 0 & +1\\
		-2 & 0 & +2\\
		-1 & 0 & +1
	\end{bmatrix}
	* \textbf{A},\ 
	\textbf{G}_y =
	\begin{bmatrix}
		+1 & +2 & +1\\
		0 & 0 & 0\\
		-1 & -2 & -1
	\end{bmatrix}
	* \textbf{A}
\end{equation}

\begin{equation}
	\textbf{G} = \sqrt{\textbf{G}_x^2 + \textbf{G}_y^2}
\end{equation}

Матрица \textbf{G} описывает значение градиента в каждом пикселе. Однако для дальнейшего шага потребуются матрицы $\textbf{G}_x, \textbf{G}_y$. Далее нужно посчитать дивергенцию полученного градиента. Для каждой матрицы градиента необходимо посчитать приблизительное значение дивергенции по каждой координате. Для каждого пикселя в матрице вычислим его частную производную. Это можно сделать, вычислив разницу между значением этого пикселя и средним значением его соседей.

\begin{equation}
	\text{div} f_{i,j} = f_{i,j} - \dfrac{f_{i-1,j} + f_{i+1,j} + f_{i,j-1} + f_{i,j+1}}{4}
\end{equation}

Получив две матрицы дивергенции, необходимо их сложить, чтобы получить матрицу лапласиана. 
\begin{equation}
	L = \nabla F = \text{div} \textbf{G} = \frac{\partial \textbf{G}_x}{\partial x} + \frac{\partial \textbf{G}_y}{\partial y}
\end{equation}

Следующим этапом после вычисления матрицы лапласиана является нахождение выборочной дисперсии значений этой матрицы. Именно это значение и будет мерой четкости/резкости изображения.

Для того, чтобы определить положение фокуса, необходимо проделать упомянутые выше шаги для набора снимков и выбрать тот, который имеет наибольшее по абсолютной величине значение дисперсии лапласиана, так как это будет означать максимальные перепады интенсивности, а значит, наиболее выраженные края и границы объекта съемки.

Очевидно, этот подход имеет много недостатков:
\begin{itemize}
	\item Малая скорость работы. Алгоритм требует целого набора изображений на вход, на съемку которого затрачивается сравнительно много времени.
	\item Индивидуальная настройка для каждого объектива/камеры. Необходимо сделать серию снимков, выбрать самый качественный из них и вернуть камеру в это положение. Очевидно, что для объективов с большим коэффициентом увеличения разница положений камеры между двумя соседними снимками должна быть меньше, чем для объективов с малым увеличением. При этом диапазон расстояний для любой конфигурации должен быть примерно одинаковым.
	\item Невысокая точность. У данного алгоритма она ограничивается шагом сдвига камеры по оси $z$, так как истинное положение фокальной плоскости может оказаться между двумя зарегистрированными положениями камеры. Тогда в худшем случае ошибка вычисления составит $\dfrac{s}{2}$, где $s$ -- величина шага по вертикали.
\end{itemize}

\subsection{Фазовый автофокус} % ~ нужен, чтобы избавиться от висячего предлога (союза) в конце строки
\begin{figure}[ht!] 
	\center
	\includegraphics [scale=1] {my_folder/images/phase_focus_detecror.png}
	\caption{Устройство фазового автофокуса. 72 - конденсор; 8 - датчик; 80, 81 - ПЗС-линейки; 30 - зрачок объектива; 31, 32 - области зрачка; 75 - маска; 76, 77 - микрообъективы для датчика; 70 - окно, ограничивающее размер изображения; 71 - рамка конденсора.}
	\label{fig:pdaf}
\end{figure}

Принцип работы фазового автофокуса следующий: в матрицу (\firef{fig:pdaf}) встроен фазовый датчик (8) с двумя линейками (80, 81), в которые приходят световые потоки с противоположных областей (31 и 32) зрачка (30) объектива через микрообъективы (76 и 77). Если объект в фокусе,  изображения объекта находятся в центрах соседних ПЗС-линеек. Таким образом, сигналы, получаемые процессором с разных линеек, совпадают (находятся <<в фазе>>). Если же объектив не сфокусирован на объекте съемки, то изображения смещаются внутрь или наружу линеек. Сигналы перестают совпадать и имеют разность фаз (\firef{fig:phase_images}). На основе этой разности фаз считается фазовый сдвиг, а далее -- необходимое смещение для системы линз.

\begin{figure}[!htbp]
	\begin{subfigure}[t]{0.45\linewidth}
		\centering
		\includegraphics[width=.85\linewidth]{my_folder/images/phase_image_1}
		\caption{}
		\label{fig:phase_image-a}
	\end{subfigure}
	\hfill
	\begin{subfigure}[t]{0.45\linewidth}
		\centering
		\includegraphics[width=.85\linewidth]{my_folder/images/phase_image_2}
		\caption{}
		\label{fig:phase_image-b}
	\end{subfigure}
	\\
	\begin{subfigure}[t]{0.45\linewidth}
		\centering
		\includegraphics[width=.85\linewidth]{my_folder/images/phase_image_3}
		\caption{}
		\label{fig:phase_image-c}
	\end{subfigure}
	\hfill
	\begin{subfigure}[t]{0.45\linewidth}
		\centering
		\includegraphics[width=.85\linewidth]{my_folder/images/phase_image_4}
		\caption{}
		\label{fig:phase_image-d}
	\end{subfigure}
	\caption{Снимки и срезы их фазовых изображений: {\itshape a} --- снимок объекта в фокусе; {\itshape b} --- снимок объекта не в фокусе; {\itshape c} --- срез фазового изображения, когда объект в фокусе; {\itshape d} --- срез фазового изображения, когда объект не в фокусе}
	\label{fig:phase_images}  
\end{figure}

\textit{ПЗС-линейка} -- специализированная аналоговая интегральная микросхема, состоящая из светочувствительных фотодиодов, выполненная на основе кремния, использующая технологию ПЗС -- приборов с зарядовой связью (полупроводниковых приборов, в которых применяется технология управляемого переноса заряда в объёме полупроводника).

Для PDAF знак фазового сдвига определяет направление движения линзы, а величина фазового сдвига определяет расстояние перемещения линзы. Фазовый сдвиг положителен, если фокальная плоскость находится перед объектом, и отрицателен, если фокальная плоскость находится позади объекта. Чем дальше объект от фокальной плоскости, тем больше абсолютная величина фазового сдвига.

Однако оценка фазового сдвига редко бывает безошибочной. Шум датчика, размытие изображения и низкая текстура часто влияют на точность и надежность оценки фазового сдвига. Хотя ошибку оценки фазового сдвига можно уменьшить, применив фильтр Гаусса к фазовой корреляции, по-прежнему трудно получить точную оценку фазового сдвига, когда объектив находится далеко от сфокусированного положения линзы. Другая заметная проблема PDAF заключается в том, что ошибка оценки фазового сдвига может накапливаться в процессе принятия решения о движении линзы.

Для оценки фазового сдвига в частотной области обычно используется фазовая корреляция. Он применяется для поиска соответствия между смещенными, повернутыми и разномасштабными изображениями. Но этот метод может легко потерпеть неудачу при работе с размытыми или зашумленными изображениями. Чтобы решить эту проблему, было решено применять фильтр Гаусса и использовать разность Гауссианов для извлечения признаков.

В параксиальном и тонколинзовом приближениях формирования изображения глубина объекта D связана с фазовым сдвигом s соотношением \cite{AF-Net}
\begin{equation}
	s = A\left( \frac{1}{z} - \frac{1}{D}\right),
	\label{eq:p_phase_shift_s}
\end{equation}
где $A$ -- некоторая константа, $z$ -- расстояние от фокальной плоскости до линзы. Когда объект находится в фокусе, $z = D$. Однако уравнение (\ref{eq:p_phase_shift_s}) может не выполняться при наличии ошибки оценки фазового сдвига. К этому может приводить ситуация, когда левый и правый фазовые датчики расположены слишком далеко друг от друга.

В качестве решения данной проблемы предлагается использовать статистический метод, который сначала получает распределение вероятностей оптимального расстояния хорда линзы для заданного фазового сдвига на этапе калибровки, а затем использует его для определения расстояния хода линзы при тестировании.

\subsection{Фазовый сдвиг}
Для идеальной пары левого и правого фазового изображения с фазовым сдвигом $\Delta x$ выполняется следующее:
\begin{equation}
	r(x, y) = l(x + \Delta x, y),
\end{equation}
где $(x, y)$ -- координаты пикселя, $r(\cdot,\cdot)$ и $l(\cdot,\cdot)$ -- правые и левое фазовые изображения соответственно.

Фазовый сдвиг между левым и правым изображениями можно получить с помощью фазовой корреляции \cite{PhaseCorrelation}. Пусть $L$ и $R$ -- двумерное преобразование Фурье для левого и правого фазовых изображений соответственно. Для этого найдем корреляционную матрицу $p(x, y)$.
\begin{equation}
	p(x, y) = F^{-1} \left\{ \frac{L \circ \overline{R}}{\left| L \circ R \right|} \right\}
\end{equation}
где $F^{-1}$ -- обратное двумерное преобразование Фурье, <<$\circ$>> -- поэлементное умножение матриц, <<$\overline{\cdot}$>> -- комплексное сопряжение.

Далее рассматриваем корреляционную прямую $p(x,0)$. Аргумент $y$ принят равным нулю, поскольку матрицу значение $p(x,y)$ соответствует корреляции при сдвиге на $x$ и $y$ по соответствующим осям. В данном случае сдвиг производится лишь по одной оси, поэтому второй аргумент равен нулю. Однако шум от датчиков может приводить к нескольким пикам в корреляционной матрице. Чтобы этого избежать, применим сглаживание корреляционной кривой $p(x,0 )$ Гауссовым ядром $g(x)$:
\begin{equation}
	p_f(x) = g(x) * p(x, 0),
\end{equation}
где $p_f(x)$ -- исправленная корреляционная кривая. Тогда фазовый сдвиг $\Delta x$ определяется как
\begin{equation}
	\Delta x = \text{arg} \max_x p_f(x)
\end{equation} 

Если построить график фазового сдвига в зависимости от положения линзы, полученная кривая будет называться профилем фазового сдвига. Положение линзы, соответствующее нулевому фазовому сдвигу, является положением линзы в фокусе. Аналогично, если мы построим график контрастности изображения в зависимости от положения линзы, получим профиль фокуса (\firef{fig:phse_profile}). На нем положение линзы в фокусе соответствует максимальному значению контрастности и оно совпадает с нулевым фазовым сдвигом.

\begin{figure}[ht!] 
	\center
	\includegraphics [scale=0.7] {my_folder/images/phase_profile.png}
	\caption{Фазовый профиль и профиль фокуса}
	\label{fig:phse_profile}
\end{figure}

\section{Нейросетевые методы} \label{ch1:sec2} 
Фазовый автофокус показывал отличные результаты по сравнению с более старыми методами автофокусировки. Но упомянутые выше недостатки, в частности неустойчивость к шуму, побуждали искать новые методы работы с оптикой и камерами. Кроме того с ростом интереса к нейросетям и машинному обучению были предприняты попытки использовать их и в этой области. Было предложено несколько решений, использующих глубокое обучение. Некоторые из них определяли смещение камеры на основе разности двух изображений \cite{RaiDastidar}, другие по двум снимкам генерировали виртуальный сфокусированный снимок \cite{li2020rapid}. Однако для уменьшения временных затрат на фокусировку исследования также были направлены на разработку методов, которые не требуют дополнительных перемещений камеры. Так была разработана сверточная нейронная сеть на основе алгоритма фазового автофокуса AF-Net.

\subsection{Нейросеть AF-Net}
Подход на основе глубокого обучения \cite{AF-Net} позволяет уменьшить влияние шума и ошибку, которая может накапливаться при выполнении большого числа операций с фазовыми изображениями.

На вход нейросети посутпают те же фазовые изображения (левое и правое), на выходе получается вещественное число со знаком, которое обозначает направление и величину смещения линзы для достижения состояния максимальной четкости. Архитектура сети выглядит следующим образом:

\begin{table}[!htbp]
	\centering
	\small
	\begin{tabular}{|p{2.5cm}<{\centering}|p{2.5cm}<{\centering}|p{2.5cm}<{\centering}|p{3.5cm}<{\centering}|p{3.5cm}<{\centering}|}
		\hline
		\multicolumn{5}{|c|}{Выделение признаков} \\ \hline
		Названия слоя & Ядро & Шаг ядра & входные/выходные каналы & входной/выходной размер\\ \hline
		conv0 & $5 \times 5$ & $2 \times 2$ & 2/64 & $33 \times 33$/ $16 \times 16$ \\ \hline
		conv1 & $3 \times 3$ & $1 \times 1$ & 64/128 & $16 \times 16$/ $16 \times 16$ \\ \hline
		conv2 & $3 \times 3$ & $2 \times 2$ & 128/128 & $16 \times 16$/ $8 \times 8$ \\ \hline
		conv2 & $3 \times 3$ & $2 \times 2$ & 128/256 & $8 \times 8$/ $4 \times 4$ \\ \hline
		\multicolumn{5}{|c|}{Полносвязные слои} \\ \hline
		Название слоя & \multicolumn{2}{c|}{Входные/выходные размеры} & \multicolumn{2}{c|}{Функция активации} \\ \hline
		fc0 & \multicolumn{2}{c|}{4096/256} & \multicolumn{2}{c|}{ReLU} \\ \hline
		fc1 & \multicolumn{2}{c|}{256/64} & \multicolumn{2}{c|}{ReLU} \\ \hline
		fc2 & \multicolumn{2}{c|}{64/1} & \multicolumn{2}{c|}{Линейная} \\ \hline
	\end{tabular}
	\caption{Архитектура нейросети}
	\label{tab:CNN_struct}
\end{table}

После каждого сверточного слоя следует функция активации ReLU и пакетная нормализация (batch normalization). Используется оптимизатор Adamax, размер батча равен 128, параметры оптимизатора $\beta_1 = 0.5,\ \beta_2 = 0.999$, learning rate равен 0.001. Также процесс обучения было принято останавливать, когда потери не уменьшаются в течение 20 эпох. В среднем процесс обучения задействует 80 эпох.

\section{Сравнение статистического и нейросетевого метода}
Сравним AF-Net с классическим методом фазового автофокуса, используя следующие метрики: коэффициент успеха (success rate), количество перемещений линзы до остановки процесса и ошибка конечного положения линзы. Сравним на разных начальных положениях линзы. Обозначим нулем положение линзы в фокусе, положительное смещение - это перемещение линзы ближе к объекту, отрицательное - дальше от объекта, чем положение в фокусе. Результаты:

\begin{table}[!htbp]
	\centering
	\small
	\begin{tabular}{|c|c|c|c|c|c|c|c|}
		\hline
		\multirow{2}{*}{Метод}& \multirow{2}{*}{Метрика} & \multicolumn{6}{c|}{начальное положение линзы} \\
		\cline{3-8} & & -30 & -20 & -10 & 10 & 20 & 30\\ \hline
		\multirow{3}{*}{AF-Net} & Success rate & 90.48 & 94.83 & 95.06 & 97.26 & 100.0 & 100.0\\ 
		\cline{2-8} & final lens position error & 1.381 & 1.207 & 1.185 & 1.027 & 0.981 & 0.826 \\
		\cline{2-8} & number of lens movements & 2.26 & 2.20 & 2.03 & 2.06 & 2.06 & 2.00\\ \hline
		\multirow{3}{*}{Статистический} & Success rate & 23.81 & 46.55 & 51.85 & 63.01 & 57.41 & 43.48\\ 
		\cline{2-8} & final lens position error & 10.57 & 5.741 & 4.000 & 3.342 & 3.426 & 3.261 \\
		\cline{2-8} & number of lens movements & 3.40 & 3.00 & 2.21 & 2.21 & 2.54 & 2.60\\ \hline
	\end{tabular}
	\caption{Сравнение метрик AF-Net и статистического метода}
	\label{tab:Comparison}
\end{table}

Также сравним их производительность:

\begin{table}[!htbp]
	\centering
	\small
	\begin{tabular}{|c|p{4cm}<{\centering}|p{4cm}<{\centering}|p{4cm}<{\centering}|}
		\hline
		Метод & Максимальная ошибка положения линзы & Максимальное количество перемещений линзы & Среднее время расчета одного перемещения (мс)\\ \hline
		AF-Net & 5 & 4 & 10.8\\ \hline
		Статистический & 12 & 7 & 28.3 \\ \hline
	\end{tabular}
	\caption{Оценка производительности}
	\label{tab:performance}
\end{table}


\section{Выводы} \label{ch1:conclusion}

Из сводных сравнительных таблиц хорошо видно, что нейросетевой подход превосходит классический как в метриках качества, так и по производительности. Это означает, что применение AF-Net оправдано, и благодаря ему, фокусировка будет проходить быстрее и точнее. Но автофокусировка, основанная на фазовых изображениях и фазовом сдвиге, имеет существенный недостаток -- она требует интеграции непосредственно в камеру, так как предполагается, что такой алгоритм является частью ПО камеры. Он использует показания фазовых датчиков. Но зачастую подключиться к ним извне нет возможности, или же эти датчики отсутствуют вовсе.